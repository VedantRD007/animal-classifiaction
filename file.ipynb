{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade keras-cv\n",
    "!pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import ops\n",
    "from keras import optimizers\n",
    "from keras.optimizers import schedules\n",
    "from keras import metrics\n",
    "\n",
    "import keras_cv\n",
    "\n",
    "# Import tensorflow for `tf.data` and its preprocessing functions\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = \"file path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "train_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dir_path,  color_mode='rgb',label_mode='int',\n",
    "    image_size=IMAGE_SIZE,batch_size=BATCH_SIZE, shuffle=True,subset='training',validation_split=0.2,\n",
    "    seed=25)\n",
    "validation_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dir_path, color_mode='rgb',\n",
    "    label_mode='int',image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,shuffle=False,subset='validation',validation_split=0.2,\n",
    "    seed=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class_names = train_generator.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_ds_shuff = train_generator.shuffle(\n",
    "    3*BATCH_SIZE, reshuffle_each_iteration=True\n",
    ")\n",
    "images = next(iter(train_ds_shuff.take(1)))[0]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_train_ds = train_generator.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_test_ds = validation_generator.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(keras_cv.models.ImageClassifier.presets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = keras_cv.models.ImageClassifier.from_preset(\n",
    "    \"resnet50_v2_imagenet\", num_classes=len(class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = keras_cv.models.ImageClassifier.from_preset(\n",
    "    \"resnet50_v2_imagenet\", num_classes=len(class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "checkpoint_filepath = 'model/weights-improvement-{epoch:02}-{val_loss:.4f}.keras'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                     filepath=checkpoint_filepath,\n",
    "                     verbose=2, monitor='val_acc', mode='max',\n",
    "                     save_best_only=True\n",
    "                 )\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=15,\n",
    "                        verbose=2, restore_best_weights=True)\n",
    "model.compile(optimizer=AdamW(learning_rate=0.001),loss='sparse_categorical_crossentropy',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "r = model.fit(normalized_train_ds,\n",
    "              validation_data=normalized_test_ds, callbacks=[model_checkpoint_callback],\n",
    "              epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model file path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "logloss, acc = model.evaluate(normalized_test_ds)\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Logloss: \", logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(r.history['acc'], label='Accuracy')\n",
    "plt.plot(r.history['val_acc'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "path = \"path of image\"\n",
    "image = Image.open(path)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image = np.array(image)\n",
    "\n",
    "# Normalize the image\n",
    "image = image / 255.0\n",
    "\n",
    "# Add a batch dimension\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "resizing = keras_cv.layers.Resizing(\n",
    "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "np_im_rs = resizing(image)\n",
    "np_im_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np_im_rs)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Top class is:\", class_names[np.argmax(predictions[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('/content/drive/MyDrive/Internship/anim_class_model.weights.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
